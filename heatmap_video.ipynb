{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "o4vDP0WTcl5V"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/kvasir_resnet.h5 ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "\n",
        "import tensorflow.keras as K\n",
        "     \n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "     "
      ],
      "metadata": {
        "id": "IdRRpJwLgPd4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model(\"kvasir_resnet.h5\")\n",
        "last_conv_layer = next(x for x in model.layers[::-1] if isinstance(x, K.layers.Conv2D))"
      ],
      "metadata": {
        "id": "igjrBX4njVHf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "last_conv_layer.name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6t1gYhj2jWc2",
        "outputId": "e06a546c-1052-49e4-88b3-e1cf53fde5be"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'conv5_block3_3_conv'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the model\n",
        "model = keras.models.load_model(\"kvasir_resnet.h5\")\n",
        "\n",
        "# Define the gradcam function\n",
        "def gradcam(model, img, layer_name):\n",
        "  # Define the gradient model\n",
        "  grad_model = keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "\n",
        "  # Compute the gradient of the top predicted class for our input image\n",
        "  with tf.GradientTape() as tape:\n",
        "    conv_output, predictions = grad_model(np.array([img]))\n",
        "    loss = predictions[:, np.argmax(predictions[0])]\n",
        "    grads = tape.gradient(loss, conv_output)[0]\n",
        "\n",
        "  # Compute the guided gradients\n",
        "  guided_grads = (tf.cast(conv_output > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads)\n",
        "\n",
        "  # Get the convolution output and guided gradients\n",
        "  conv_output = conv_output[0]\n",
        "  guided_grads = guided_grads[0]\n",
        "\n",
        "  # Compute the weights using global average pooling\n",
        "  weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "\n",
        "  # Create a heatmap using the weights and conv output\n",
        "  cam = np.zeros(dtype=np.float32, shape=conv_output.shape[0:2])\n",
        "  for i, w in enumerate(weights):\n",
        "    cam += w * conv_output[:, :, i]\n",
        "\n",
        "  # Normalize the heatmap\n",
        "  cam = cv2.resize(cam.numpy(), (img.shape[1], img.shape[0]))\n",
        "  cam = np.maximum(cam, 0)\n",
        "  heatmap = cam / np.max(cam)\n",
        "\n",
        "  # Convert the heatmap to RGB\n",
        "  heatmap = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)\n",
        "\n",
        "  # Overlay the heatmap on the original image\n",
        "  overlay = cv2.addWeighted(cv2.cvtColor(img.astype('uint8'), cv2.COLOR_RGB2BGR), 0.7, heatmap, 0.3, 0)\n",
        "\n",
        "  return overlay\n",
        "\n",
        "\n",
        "# Define the video input and output paths\n",
        "video_input_path = \"video.mp4\"\n",
        "video_output_path = \"output_video.mp4\"\n",
        "\n",
        "# Define the layer name to visualize\n",
        "layer_name = \"conv5_block3_out\"\n",
        "\n",
        "# Load the video\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "# Get the video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = 224\n",
        "height = 224\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(video_output_path, fourcc, fps, (224, 224))\n",
        "\n",
        "# Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "  # Read a frame from the video\n",
        "  ret, frame = cap.read()\n",
        "  \n",
        "  if ret == True:\n",
        "    # Preprocess the frame\n",
        "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    #frame = cv2.resize(frame, (128, 128))\n",
        "    #frame = np.array(frame, dtype=np.float32)\n",
        "\n",
        "\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frame = np.array(frame, dtype=np.float32)\n",
        "    #frame = frame / 255.0  # normalize pixel values to [0, 1]\n",
        "    # Apply any other preprocessing steps that you used during training of the model\n",
        "    #frame = keras.applications.resnet50.preprocess_input(frame)\n",
        "       # Apply the gradcam function to the frame\n",
        "    guided_cam = gradcam(model, frame, layer_name)\n",
        "    \n",
        "    # Convert the guided_cam to BGR\n",
        "    guided_cam = cv2.cvtColor(guided_cam, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "    # Write the frame to the output video\n",
        "    out.write(guided_cam)\n",
        "    \n",
        "    # Display the resulting frame\n",
        "    #cv2.imshow('Frame',guided_cam)\n",
        "    \n",
        "    # Press Q on keyboard to exit\n",
        "    #if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "      #break\n",
        "  \n",
        "  # Break the loop\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all the frames\n",
        "cv2.destroyAllWindows()\n",
        "    \n",
        "     "
      ],
      "metadata": {
        "id": "V_T7V3XQgItu"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}