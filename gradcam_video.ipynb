{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OkX3o7hp0cON"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/kvasir_resnet.h5 ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "AEW1FF0rYduy"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# Load the model\n",
        "model = keras.models.load_model(\"kvasir_resnet.h5\")\n",
        "\n",
        "# Define the gradcam function\n",
        "def gradcam(model, img, layer_name):\n",
        "  # Define the gradient model\n",
        "  grad_model = keras.models.Model([model.inputs], [model.get_layer(layer_name).output, model.output])\n",
        "  \n",
        "  # Compute the gradient of the top predicted class for our input image\n",
        "  with tf.GradientTape() as tape:\n",
        "    conv_output, predictions = grad_model(np.array([img]))\n",
        "    loss = predictions[:, np.argmax(predictions[0])]\n",
        "    grads = tape.gradient(loss, conv_output)[0]\n",
        "  \n",
        "  # Compute the guided gradients\n",
        "  guided_grads = (tf.cast(conv_output > 0, \"float32\") * tf.cast(grads > 0, \"float32\") * grads)\n",
        "  \n",
        "  # Get the convolution output and guided gradients\n",
        "  conv_output = conv_output[0]\n",
        "  guided_grads = guided_grads[0]\n",
        "  \n",
        "  # Compute the weights using global average pooling\n",
        "  weights = tf.reduce_mean(guided_grads, axis=(0, 1))\n",
        "  \n",
        "  # Create a 7x7 heat map from the weights and conv output\n",
        "  cam = np.ones(conv_output.shape[0:2], dtype=np.float32)\n",
        "  for i, w in enumerate(weights):\n",
        "    cam += w * conv_output[:, :, i]\n",
        "  \n",
        "  # Resize the cam to the original image size\n",
        "  cam = cv2.resize(cam.numpy(), (img.shape[1], img.shape[0]))\n",
        "  \n",
        "  # Normalize the cam\n",
        "  cam = cam - np.min(cam)\n",
        "  cam = cam / np.max(cam)\n",
        "  \n",
        "  # Convert the cam to 3-dimensions\n",
        "  cam3 = np.expand_dims(cam, axis=2)\n",
        "  cam3 = np.tile(cam3,[1,1,3])\n",
        "\n",
        "  # Apply the cam as a mask to the original image and get the visualized image\n",
        "  guided_cam = (cam3 * img.astype(\"float32\"))\n",
        "  guided_cam = guided_cam / np.max(guided_cam)\n",
        "  guided_cam = (guided_cam * 255).astype(np.uint8)\n",
        "\n",
        "  return guided_cam\n",
        "\n",
        "# Define the video input and output paths\n",
        "video_input_path = \"video.mp4\"\n",
        "video_output_path = \"output_video.mp4\"\n",
        "\n",
        "# Define the layer name to visualize\n",
        "layer_name = \"conv5_block3_out\"\n",
        "\n",
        "# Load the video\n",
        "cap = cv2.VideoCapture(video_input_path)\n",
        "\n",
        "# Get the video properties\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "width = 224\n",
        "height = 224\n",
        "\n",
        "# Define the codec and create VideoWriter object\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(video_output_path, fourcc, fps, (224, 224))\n",
        "\n",
        "# Read until video is completed\n",
        "while(cap.isOpened()):\n",
        "  # Read a frame from the video\n",
        "  ret, frame = cap.read()\n",
        "  \n",
        "  if ret == True:\n",
        "    # Preprocess the frame\n",
        "    #frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    #frame = cv2.resize(frame, (128, 128))\n",
        "    #frame = np.array(frame, dtype=np.float32)\n",
        "\n",
        "\n",
        "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frame = np.array(frame, dtype=np.float32)\n",
        "    #frame = frame / 255.0  # normalize pixel values to [0, 1]\n",
        "    # Apply any other preprocessing steps that you used during training of the model\n",
        "    #frame = keras.applications.resnet50.preprocess_input(frame)\n",
        "       # Apply the gradcam function to the frame\n",
        "    guided_cam = gradcam(model, frame, layer_name)\n",
        "    \n",
        "    # Convert the guided_cam to BGR\n",
        "    guided_cam = cv2.cvtColor(guided_cam, cv2.COLOR_RGB2BGR)\n",
        "    \n",
        "    # Write the frame to the output video\n",
        "    out.write(guided_cam)\n",
        "    \n",
        "    # Display the resulting frame\n",
        "    #cv2.imshow('Frame',guided_cam)\n",
        "    \n",
        "    # Press Q on keyboard to exit\n",
        "    #if cv2.waitKey(25) & 0xFF == ord('q'):\n",
        "      #break\n",
        "  \n",
        "  # Break the loop\n",
        "  else:\n",
        "    break\n",
        "\n",
        "# Release the video capture and writer objects\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "# Close all the frames\n",
        "cv2.destroyAllWindows()\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}